{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03135afc-7d00-481a-aa52-9320d7c508d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 09:09:22.973886: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-28 09:09:23.239538: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735376963.337267     391 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735376963.365220     391 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-28 09:09:23.610493: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.layers import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d789a5-5ec0-4b11-b1a5-ed5a7a61d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from ukr.txt\n",
      "Stop next to the school.\tЗупиніть біля школи.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1572093 (fanty) & #6451672 (deniko)\n",
      "Tom slipped on the ice and fell.\tТом послизнувся на кризі та впав.\tCC-BY 2.0 (France) Attribution: tatoeba.org #6076668 (CK) & #5812016 (deniko)\n",
      "Tom is being bullied by Mary.\tМері цькує Тома.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1398212 (Spamster) & #6289146 (deniko)\n",
      "\n",
      "Sample from text_pairs\n",
      "('Do you have a map of Australia?', '[s] У тебе є мапа Австралії? [e]')\n",
      "('Do you like my T-shirt?', '[s] Тобі подобається моя футболка? [e]')\n",
      "('I lit three candles.', '[s] Я запалив три свічки. [e]')\n",
      "('Tom drank a cup of coffee.', '[s] Том випив чашку кави. [e]')\n",
      "('Bye, Tom.', '[s] Бувайте, Томе. [e]')\n"
     ]
    }
   ],
   "source": [
    "with open('ukr.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')[:-1]\n",
    "\n",
    "print(\"Data from ukr.txt\")\n",
    "for _ in range(3):\n",
    "    print(random.choice(lines))\n",
    "\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    eng, ukr, _ = line.split('\\t')\n",
    "    ukr = '[s] ' + ukr + ' [e]'\n",
    "    text_pairs.append((eng, ukr))\n",
    "\n",
    "print(\"\\nSample from text_pairs\")\n",
    "for t in range(5):\n",
    "    print(random.choice(text_pairs))\n",
    "\n",
    "random.shuffle(text_pairs)\n",
    "text_pairs = text_pairs[:50000]\n",
    "num_val = int(0.15 * len(text_pairs))\n",
    "num_train = len(text_pairs) - 2 * num_val\n",
    "train_pairs = text_pairs[:num_train]\n",
    "val_pairs = text_pairs[num_train: num_train + num_val]\n",
    "test_pairs = text_pairs[num_train + num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87c5bfe5-1900-4af5-b40b-733e0c8be7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735376968.045228     391 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9517 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6417\n",
      "[np.str_('do'), np.str_('im'), np.str_('have'), np.str_('dont'), np.str_('me'), np.str_('was'), np.str_('he'), np.str_('mary'), np.str_('in'), np.str_('it')]\n",
      "15000\n",
      "[np.str_('на'), np.str_('Мері'), np.str_('ти'), np.str_('Тома'), np.str_('я'), np.str_('з'), np.str_('у'), np.str_('Це'), np.str_('У'), np.str_('в')]\n"
     ]
    }
   ],
   "source": [
    "strip_chars = string.punctuation.replace('[', '')\n",
    "strip_chars = strip_chars.replace(']', '')\n",
    "\n",
    "vocabulary_size = 15000\n",
    "sequence_length = 20\n",
    "batch_size = 64\n",
    "\n",
    "def ukr_standardization(input_string):\n",
    "    return tf.strings.regex_replace(tf.strings.lower(input_string), '[%s]' % re.escape(strip_chars), '')\n",
    "\n",
    "eng_vector = keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "ukr_vector = keras.layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=ukr_standardization,\n",
    ")\n",
    "train_eng = [pair[0] for pair in train_pairs]\n",
    "train_ukr = [pair[1] for pair in train_pairs]\n",
    "eng_vector.adapt(train_eng)\n",
    "ukr_vector.adapt(train_ukr)\n",
    "\n",
    "for v in [eng_vector, ukr_vector]:\n",
    "    print(len(v.get_vocabulary()))\n",
    "    print(v.get_vocabulary()[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3e75be7-3620-4eaa-8344-96116d49ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(eng, ukr):\n",
    "    eng = eng_vector(eng)\n",
    "    ukr = ukr_vector(ukr)\n",
    "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": ukr[:, :-1]}, ukr[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, ukr_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    ukr_texts = list(ukr_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, ukr_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.cache().shuffle(2048).prefetch(16)\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e96fe01-1916-4be4-a3fc-e97bf070b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder inputs shape: (64, 20)\n",
      "decoder inputs shape: (64, 20)\n",
      "targets shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-28 09:09:29.764436: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'encoder inputs shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'decoder inputs shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1419504a-dff2-44a4-b5df-581a70ee0932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерація позиційного кодування\n",
    "def get_positional_encoding(seq_len, embed_dim):\n",
    "    position = tf.range(seq_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "    div_term = tf.exp(tf.range(0, embed_dim, 2, dtype=tf.float32) * -(tf.math.log(10000.0) / embed_dim))\n",
    "    \n",
    "    sinusoidal = tf.concat([tf.sin(position * div_term), tf.cos(position * div_term)], axis=-1)\n",
    "    return sinusoidal\n",
    "\n",
    "# Оновлення класів TransformerEncoder та TransformerDecoder з додаванням позиційного кодування\n",
    "class TransformerEncoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, latent_dim):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.latent_dim = latent_dim\n",
    "        self.attention = MultiHeadAttention(num_heads, embed_dim)  # Assuming you have this implemented\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        pos_encoding = get_positional_encoding(seq_len, self.embed_dim)\n",
    "        inputs = inputs + pos_encoding  # Add positional encoding to the input\n",
    "        attn_output = self.attention(inputs, inputs)  # Example attention mechanism\n",
    "        return attn_output\n",
    "\n",
    "class TransformerDecoder(keras.layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.attention1 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention2 = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = tf.keras.Sequential([keras.layers.Dense(ff_dim, activation=\"relu\"), keras.layers.Dense(embed_dim)])\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "        self.dropout3 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, enc_output, training=False):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        pos_encoding = get_positional_encoding(seq_len, inputs.shape[-1])\n",
    "        inputs = inputs + pos_encoding\n",
    "        attn_output1 = self.attention1(inputs, inputs)\n",
    "        attn_output1 = self.dropout1(attn_output1, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output1)\n",
    "        attn_output2 = self.attention2(out1, enc_output)\n",
    "        attn_output2 = self.dropout2(attn_output2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn_output2)\n",
    "        ffn_output = self.dense_proj(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        return self.layernorm3(out2 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb5a1dae-b709-403e-8632-33a75cd50d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "latent_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.layers.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
    "x = keras.layers.Embedding(input_dim=vocabulary_size, output_dim=embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, num_heads, latent_dim)(x, training=True)\n",
    "\n",
    "decoder_inputs = keras.layers.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
    "x = keras.layers.Embedding(input_dim=vocabulary_size, output_dim=embed_dim)(decoder_inputs)\n",
    "\n",
    "x = TransformerDecoder(embed_dim, num_heads, latent_dim)(x, encoder_outputs, training=True)\n",
    "decoder_outputs = keras.layers.Dense(vocabulary_size, activation=\"softmax\")(x)\n",
    "\n",
    "transformer = keras.models.Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee085c3e-4cb0-4d5e-8a79-0268252d0b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735376972.353505     476 service.cc:148] XLA service 0x7ff2c405c1a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735376972.353941     476 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 SUPER, Compute Capability 8.9\n",
      "2024-12-28 09:09:32.438020: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "W0000 00:00:1735376972.540279     476 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "I0000 00:00:1735376972.892994     476 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-28 09:09:34.436503: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:34.685591: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:34.940160: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:34.948472: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 1892 bytes spill stores, 2348 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:35.029117: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:35.328392: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:35.932055: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 88 bytes spill stores, 88 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:36.112135: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:36.207837: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22', 1336 bytes spill stores, 1828 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:36.301840: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 1580 bytes spill stores, 2116 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:36.473128: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:36.979020: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 312 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.000779: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19_0', 776 bytes spill stores, 724 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.270235: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21_0', 692 bytes spill stores, 636 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.336845: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24', 260 bytes spill stores, 260 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.457134: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24', 1336 bytes spill stores, 1828 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.818987: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:37.946580: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_83', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:38.018157: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:38.330245: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:39.337284: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 528 bytes spill stores, 528 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:39.565961: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45_0', 332 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:39.600788: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75_0', 808 bytes spill stores, 776 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:39.908234: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:39.990164: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37', 116 bytes spill stores, 116 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:40.260866: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73_0', 328 bytes spill stores, 316 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:40.314900: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 108 bytes spill stores, 108 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:40.473043: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:40.925630: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37_0', 332 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:41.933571: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 256 bytes spill stores, 256 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:41.942033: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 24 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:41.972169: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39_0', 660 bytes spill stores, 624 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:42.033380: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 216 bytes spill stores, 216 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/547\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 82ms/step - accuracy: 0.1855 - loss: 8.9735       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735376989.398262     476 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m214/547\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6929 - loss: 3.2297 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735376995.365197     477 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-12-28 09:09:57.159187: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 624 bytes spill stores, 820 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:57.551542: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 196 bytes spill stores, 196 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:57.559529: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 880 bytes spill stores, 1712 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:57.568317: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:57.724444: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_74', 740 bytes spill stores, 436 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:57.946858: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 312 bytes spill stores, 312 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.083959: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19_0', 756 bytes spill stores, 444 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.130543: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 80 bytes spill stores, 80 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.280893: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_67', 144 bytes spill stores, 296 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.548591: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.559649: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 236 bytes spill stores, 236 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:58.876881: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22_0', 644 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:59.144877: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_45_0', 332 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:59.274322: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21_0', 944 bytes spill stores, 644 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:59.284471: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:59.771782: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_24_0', 644 bytes spill stores, 356 bytes spill loads\n",
      "\n",
      "2024-12-28 09:09:59.783388: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_37_0', 332 bytes spill stores, 324 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:00.280476: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 128 bytes spill stores, 128 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:00.764272: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 32 bytes spill stores, 32 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:00.794810: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_21', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:00.883650: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:02.115651: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73_0', 728 bytes spill stores, 688 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.098834: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 192 bytes spill stores, 292 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.414485: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 280 bytes spill stores, 280 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.435158: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 344 bytes spill stores, 380 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.517883: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.532111: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39_0', 700 bytes spill stores, 648 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.563437: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_73', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.885374: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 52 bytes spill stores, 52 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.898393: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:03.906410: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75', 368 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:04.010963: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_39', 568 bytes spill stores, 568 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:04.066805: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_75_0', 780 bytes spill stores, 728 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7194 - loss: 2.5472  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735377020.064139     480 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "W0000 00:00:1735377020.918270     477 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "2024-12-28 09:10:21.964302: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 12 bytes spill stores, 12 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:22.015202: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_22_0', 352 bytes spill stores, 216 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:22.317385: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:22.805981: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19_0', 228 bytes spill stores, 228 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:22.976503: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_25_0', 184 bytes spill stores, 184 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:23.026656: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19', 244 bytes spill stores, 244 bytes spill loads\n",
      "\n",
      "2024-12-28 09:10:23.116130: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_19_0', 756 bytes spill stores, 444 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 64ms/step - accuracy: 0.7195 - loss: 2.5461 - val_accuracy: 0.7726 - val_loss: 1.5606\n",
      "Epoch 2/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - accuracy: 0.7773 - loss: 1.5848 - val_accuracy: 0.8030 - val_loss: 1.2990\n",
      "Epoch 3/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.8098 - loss: 1.3334 - val_accuracy: 0.8758 - val_loss: 0.8267\n",
      "Epoch 4/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 29ms/step - accuracy: 0.8824 - loss: 0.8511 - val_accuracy: 0.9179 - val_loss: 0.5769\n",
      "Epoch 5/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 27ms/step - accuracy: 0.9051 - loss: 0.6849 - val_accuracy: 0.9336 - val_loss: 0.4433\n",
      "Epoch 6/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.9239 - loss: 0.5155 - val_accuracy: 0.9436 - val_loss: 0.3715\n",
      "Epoch 7/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9317 - loss: 0.4450 - val_accuracy: 0.9519 - val_loss: 0.3117\n",
      "Epoch 8/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 26ms/step - accuracy: 0.9415 - loss: 0.3739 - val_accuracy: 0.9563 - val_loss: 0.2750\n",
      "Epoch 9/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9483 - loss: 0.3240 - val_accuracy: 0.9628 - val_loss: 0.2353\n",
      "Epoch 10/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9548 - loss: 0.2791 - val_accuracy: 0.9662 - val_loss: 0.2108\n",
      "Epoch 11/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.9603 - loss: 0.2432 - val_accuracy: 0.9731 - val_loss: 0.1743\n",
      "Epoch 12/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9655 - loss: 0.2092 - val_accuracy: 0.9757 - val_loss: 0.1572\n",
      "Epoch 13/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9692 - loss: 0.1836 - val_accuracy: 0.9760 - val_loss: 0.1538\n",
      "Epoch 14/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9727 - loss: 0.1617 - val_accuracy: 0.9795 - val_loss: 0.1333\n",
      "Epoch 15/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9765 - loss: 0.1401 - val_accuracy: 0.9807 - val_loss: 0.1242\n",
      "Epoch 16/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9790 - loss: 0.1252 - val_accuracy: 0.9822 - val_loss: 0.1127\n",
      "Epoch 17/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9819 - loss: 0.1097 - val_accuracy: 0.9839 - val_loss: 0.1042\n",
      "Epoch 18/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9805 - loss: 0.1224 - val_accuracy: 0.9852 - val_loss: 0.0959\n",
      "Epoch 19/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9867 - loss: 0.0841 - val_accuracy: 0.9853 - val_loss: 0.0945\n",
      "Epoch 20/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9890 - loss: 0.0716 - val_accuracy: 0.9873 - val_loss: 0.0826\n",
      "Epoch 21/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9910 - loss: 0.0611 - val_accuracy: 0.9878 - val_loss: 0.0802\n",
      "Epoch 22/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 23ms/step - accuracy: 0.9927 - loss: 0.0517 - val_accuracy: 0.9879 - val_loss: 0.0788\n",
      "Epoch 23/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9945 - loss: 0.0430 - val_accuracy: 0.9890 - val_loss: 0.0715\n",
      "Epoch 24/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9957 - loss: 0.0352 - val_accuracy: 0.9897 - val_loss: 0.0670\n",
      "Epoch 25/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 23ms/step - accuracy: 0.9966 - loss: 0.0284 - val_accuracy: 0.9899 - val_loss: 0.0650\n",
      "Epoch 26/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9975 - loss: 0.0221 - val_accuracy: 0.9904 - val_loss: 0.0629\n",
      "Epoch 27/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - accuracy: 0.9983 - loss: 0.0161 - val_accuracy: 0.9903 - val_loss: 0.0615\n",
      "Epoch 28/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9974 - loss: 0.0265 - val_accuracy: 0.9906 - val_loss: 0.0595\n",
      "Epoch 29/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9992 - loss: 0.0083 - val_accuracy: 0.9905 - val_loss: 0.0600\n",
      "Epoch 30/30\n",
      "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0054 - val_accuracy: 0.9910 - val_loss: 0.0570\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ff3b2be9580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 30\n",
    "\n",
    "transformer.compile(\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae1439bd-276c-4715-8ee6-b435f8fe0469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат:\n",
      "--------------------------------------------------\n",
      "INPUT: Would you please open the window?\n",
      "OUTPUT: [s] Неважливо післязавтра договір невдячним присмак захворюванням олівця павутиння павутиння вдиху недобре розуміли розуміли всіма церкви дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: I didn't notice it.\n",
      "OUTPUT: [s] знала післязавтра кішок невдячним огиди твариною твариною рублів баксів підтримки недобре недобре розуміли шостому році році усі церкви цю \n",
      "--------------------------------------------------\n",
      "INPUT: Tom told me to run.\n",
      "OUTPUT: [s] Неважливо післязавтра друже невдячним фотоальбом рублів рублів баксів баксів недобре недобре недобре худобу худобу хворіють дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: What to do next is the question.\n",
      "OUTPUT: [s] Дах пожежі невдячним фотоальбом фотоальбом твариною твариною випічки випічки недобре недобре ходьби худобу коми хворіють дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: Destroy it.\n",
      "OUTPUT: [s] Неважливо невдячним невдячним друже огиди огиди можливостями можливостями можливостями недобре недобре недобре навички тринадцятого хворіють усі в їх на на\n",
      "--------------------------------------------------\n",
      "INPUT: Are you still having fun?\n",
      "OUTPUT: [s] знала післязавтра друже друже фотоальбом рублів рублів рублів баксів недобре недобре розуміли розуміли пристрій машин році    \n",
      "--------------------------------------------------\n",
      "INPUT: Maybe there's another way?\n",
      "OUTPUT: [s] калюжу договір невдячним невдячним друже друже восьмої восьмої баксів підтримки недобре недобре худобу коми хворіють дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: I wonder if Tom is OK.\n",
      "OUTPUT: [s] Неважливо тортом друже невдячним фотоальбом твариною твариною випічки випічки недобре недобре розуміли розуміли всіма церкви дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: Why don't you let Tom do that?\n",
      "OUTPUT: [s] Неважливо тортом післязавтра присмак фотоальбом рублів твариною випічки випічки недобре недобре розуміли розуміли всіма церкви дітьми    \n",
      "--------------------------------------------------\n",
      "INPUT: Tom doesn't like to make mistakes.\n",
      "OUTPUT: [s] Неважливо тортом невдячним невдячним фотоальбом рублів твариною випічки мiсяця недобре недобре розуміли розуміли всіма церкви дітьми    \n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "ukr_vocab = ukr_vector.get_vocabulary()\n",
    "ukr_index_lookup = dict(zip(range(len(ukr_vocab)), ukr_vocab))\n",
    "max_decoded_sentence_length = 20  \n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    # Токенізація\n",
    "    tokenized_input_sentence = eng_vector([input_sentence])\n",
    "    \n",
    "    decoded_sentence = \"[s]\" \n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = ukr_vector([decoded_sentence])[:, :-1]\n",
    "        \n",
    "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
    "\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])  \n",
    "        sampled_token = ukr_index_lookup[sampled_token_index]  \n",
    "        \n",
    "        decoded_sentence += \" \" + sampled_token \n",
    "        \n",
    "        if sampled_token == \"[e]\":\n",
    "            break\n",
    "    \n",
    "    return decoded_sentence\n",
    "\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "\n",
    "print(f'Результат:\\n{\"-\"*50}')\n",
    "for _ in range(10):\n",
    "    input_sentence = random.choice(test_eng_texts)  \n",
    "    translated = decode_sequence(input_sentence)  \n",
    "    print(f'INPUT: {input_sentence}\\nOUTPUT: {translated}\\n{\"-\"*50}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820230a1-3014-4a44-9bd3-4d5f605db938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
